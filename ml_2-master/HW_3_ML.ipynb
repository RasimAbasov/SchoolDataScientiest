{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R2 - это коэффициент детерминации, который используется для оценки качества подгонки регрессионной модели к данным. Это мера, которая показывает, как хорошо модель подходит к данным и объясняет их вариацию.\n",
    "\n",
    "Значение R2 находится в диапазоне от 0 до 1, где 0 означает, что модель не объясняет никакой вариации в данных, а 1 означает, что модель объясняет всю вариацию в данных. Чем ближе значение R2 к 1, тем лучше модель подходит к данным.\n",
    "\n",
    "L1 регуляризация Lasso (Least Absolute Shrinkage and Selection Operator) - это метод регрессии, который применяет регуляризацию Лассо. Регуляризация Лассо добавляет к функции потерь (обычно среднеквадратическая ошибка) сумму модулей коэффициентов регрессии. Это приводит к уменьшению веса некоторых признаков до нуля, что позволяет производить отбор признаков и упрощать модель. В отличие от регрессии Ridge, где веса признаков стремятся к нулю, но не доходят до него, в регуляризации Лассо некоторые веса могут быть точно равны нулю.\n",
    "\n",
    "L1 регуляризация обнуляет веса, это можно использовать для прореживания модели.\n",
    "Для чего это нужно:\n",
    "• ускорение модели\n",
    "• мы знаем что есть лишние признаки(линейно зависимые, шумные)\n",
    "• данных меньше чем признаков\n",
    "\n",
    "Метод Ridge заключается в добавлении L2 регуляризации к обычной линейной регрессии, что помогает снизить влияние высоко коррелированных признаков на модель. L2 регуляризация заключается в добавлении штрафа на величину коэффициентов регрессии (кроме константы), что приводит к уменьшению их значений и позволяет уменьшить переобучение модели. Параметр регуляризации alpha в Ridge регрессии позволяет управлять силой регуляризации и выбирать оптимальное значение, чтобы достичь наилучшей производительности модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression R2 score: 0.6684825753971567\n",
      "Ridge regression R2 score: 0.6659608075261693\n",
      "Lasso regression R2 score: 0.6668687223368213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "r2_lr = lr.score(X_test, y_test)\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "r2_ridge = ridge.score(X_test, y_test)\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "r2_lasso = lasso.score(X_test, y_test)\n",
    "\n",
    "print(f\"Linear regression R2 score: {r2_lr}\")\n",
    "print(f\"Ridge regression R2 score: {r2_ridge}\")\n",
    "print(f\"Lasso regression R2 score: {r2_lasso}\")\n",
    "\n",
    "\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GridSearchCV - это метод подбора наилучших параметров модели, основанный на переборе всех возможных комбинаций параметров и выборе тех, которые дают наилучший результат.\n",
    "\n",
    "RidgeCV и LassoCV - это модификации Ridge и Lasso моделей, которые автоматически подбирают коэффициент регуляризации на основе кросс-валидаци"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge GridSearchCV : Best alpha = 1e-05\n",
      "Lasso GridSearchCV: Best alpha = 1e-05\n",
      "Ridge RidgeCV: Best alpha = 1e-05\n",
      "Lasso LassoCV: Best alpha = 1e-05\n",
      "r2_ridge: 0.6659608075261693\n",
      "r2_ridge_grid_search: 0.6684825680074256\n",
      "r2_ridge_cv: 0.6684825680074256\n",
      "------\n",
      "r2_lasso: 0.6668687223368213\n",
      "r2_lasso_grid_search: 0.6684829595885677\n",
      "r2_lasso_cv: 0.6684829595885677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Создаем объект модели\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "# Создаем сетку параметров для перебора\n",
    "param_grid = {'alpha': [10**i for i in range(-5, 6)]}\n",
    "\n",
    "# Инициализируем объект GridSearchCV\n",
    "ridge_grid_search_cv = GridSearchCV(ridge, param_grid, cv=5)\n",
    "lasso_grid_search_cv = GridSearchCV(lasso, param_grid, cv=5)\n",
    "\n",
    "# Обучаем модели на обучающей выборке\n",
    "ridge_grid_search_cv.fit(X_train, y_train)\n",
    "lasso_grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_grid_search = ridge_grid_search_cv.score(X_test, y_test)\n",
    "r2_lasso_grid_search = lasso_grid_search_cv.score(X_test, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge GridSearchCV : Best alpha =\", ridge_grid_search_cv.best_params_['alpha'])\n",
    "print(\"Lasso GridSearchCV: Best alpha =\", lasso_grid_search_cv.best_params_['alpha'])\n",
    "\n",
    "\n",
    "# Инициализируем объекты RidgeCV и LassoCV\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Обучаем модели на обучающей выборке\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_cv = ridge_cv.score(X_test, y_test)\n",
    "r2_lasso_cv = lasso_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "\n",
    "print(f\"r2_ridge: {r2_ridge}\")\n",
    "print(f\"r2_ridge_grid_search: {r2_ridge_grid_search}\")\n",
    "print(f\"r2_ridge_cv: {r2_ridge_cv}\")\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(f\"r2_lasso: {r2_lasso}\")\n",
    "print(f\"r2_lasso_grid_search: {r2_lasso_grid_search}\")\n",
    "print(f\"r2_lasso_cv: {r2_lasso_cv}\")\n",
    "\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_ridge: 0.6659608075261695\n",
      "r2_ridge_grid_search: 0.6684825680074258\n",
      "r2_ridge_cv: 0.6684825680074258\n",
      "r2_ridge_standart_scaler: 0.668190107677443\n",
      "r2_ridge_min_max_scaler: 0.6762207658974593\n",
      "------\n",
      "r2_lasso: 0.6668687223368214\n",
      "r2_lasso_grid_search: 0.668482959588568\n",
      "r2_lasso_cv: 0.668482959588568\n",
      "r2_lasso_standart_scaler: 0.624044752347846\n",
      "r2_lasso_min_max_scaler: 0.2573921442545195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Создаем Pipeline для масштабирования данных и обучения Ridge/Lasso модели\n",
    "pipeline_ridge_standard_scaler = Pipeline([('scaler', StandardScaler()), ('reg', Ridge())])\n",
    "pipeline_lasso_standard_scaler = Pipeline([('scaler', StandardScaler()), ('reg', Lasso())])\n",
    "\n",
    "# Обучаем модели\n",
    "pipeline_ridge_standard_scaler.fit(X_train, y_train)\n",
    "pipeline_lasso_standard_scaler.fit(X_train, y_train)\n",
    "\n",
    "# Вычисляем R2 на тестовой выборке\n",
    "y_predict_ridge_standard_scaler = pipeline_ridge_standard_scaler.predict(X_test)\n",
    "y_predict_lasso_standard_scaler = pipeline_lasso_standard_scaler.predict(X_test)\n",
    "\n",
    "r2_ridge_standart_scaler = r2_score(y_test, y_predict_ridge_standard_scaler)\n",
    "r2_lasso_standart_scaler = r2_score(y_test, y_predict_lasso_standard_scaler)\n",
    "\n",
    "\n",
    "# Создаем Pipeline с MinMaxScaler и Ridge/Lasso\n",
    "pipeline_ridge_min_max_scaler = Pipeline([('scaler', MinMaxScaler()), ('reg', Ridge())])\n",
    "pipeline_lasso_min_max_scaler = Pipeline([('scaler', MinMaxScaler()), ('reg', Lasso())])\n",
    "\n",
    "\n",
    "# Обучаем модели\n",
    "pipeline_ridge_min_max_scaler.fit(X_train, y_train)\n",
    "pipeline_lasso_min_max_scaler.fit(X_train, y_train)\n",
    "\n",
    "# Вычисляем R2 на тестовой выборке\n",
    "y_predict_ridge_min_max_scaler = pipeline_ridge_min_max_scaler.predict(X_test)\n",
    "y_predict_lasso_min_max_scaler = pipeline_lasso_min_max_scaler.predict(X_test)\n",
    "r2_ridge_min_max_scaler = r2_score(y_test, y_predict_ridge_min_max_scaler)\n",
    "r2_lasso_min_max_scaler = r2_score(y_test, y_predict_lasso_min_max_scaler)\n",
    "\n",
    "\n",
    "print(f\"r2_ridge: {r2_ridge}\")\n",
    "print(f\"r2_ridge_grid_search: {r2_ridge_grid_search}\")\n",
    "print(f\"r2_ridge_cv: {r2_ridge_cv}\")\n",
    "print(f\"r2_ridge_standart_scaler: {r2_ridge_standart_scaler}\")\n",
    "print(f\"r2_ridge_min_max_scaler: {r2_ridge_min_max_scaler}\")\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(f\"r2_lasso: {r2_lasso}\")\n",
    "print(f\"r2_lasso_grid_search: {r2_lasso_grid_search}\")\n",
    "print(f\"r2_lasso_cv: {r2_lasso_cv}\")\n",
    "print(f\"r2_lasso_standart_scaler: {r2_lasso_standart_scaler}\")\n",
    "print(f\"r2_lasso_min_max_scaler: {r2_lasso_min_max_scaler}\")\n",
    "\n",
    "\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RidgeCV StandardScaler: Best alpha = 1.0\n",
      "Lasso LassoCV StandardScaler: Best alpha = 1e-05\n",
      "r2_ridge_standart_scaler_cv:  0.6681901076774432\n",
      "r2_lasso_standart_scaler_cv:  0.6684821312777707\n",
      "------\n",
      "Ridge RidgeCV MinMaxScaler: Best alpha = 0.1\n",
      "Lasso LassoCV MinMaxScaler: Best alpha = 1e-05\n",
      "r2_ridge_min_max_scaler_cv:  -20.66034718450295\n",
      "r2_lasso_min_max_scaler_cv:  -21.108987672687487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Создаем объекты RidgeCV и LassoCV\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Масштабируем данные\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_standard_scaled, y_train)\n",
    "lasso_cv.fit(X_train_standard_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_standart_scaler_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_standart_scaler_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV StandardScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV StandardScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(\"r2_ridge_standart_scaler_cv: \", r2_ridge_standart_scaler_cv)\n",
    "print(\"r2_lasso_standart_scaler_cv: \", r2_lasso_standart_scaler_cv)\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "# Масштабируем данные\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_min_max_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_min_max_scaled, y_train)\n",
    "lasso_cv.fit(X_train_min_max_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_min_max_scaler_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_min_max_scaler_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV MinMaxScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV MinMaxScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(\"r2_ridge_min_max_scaler_cv: \", r2_ridge_min_max_scaler_cv)\n",
    "print(\"r2_lasso_min_max_scaler_cv: \", r2_lasso_min_max_scaler_cv)\n",
    "\n",
    "\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_ridge_standart_scaler_poly: 0.8172321234956241\n",
      "r2_lasso_standart_scaler_poly: 0.7388607450771217\n",
      "------\n",
      "r2_ridge_min_max_scaler_poly: 0.8402436598340637\n",
      "r2_lasso_min_max_scaler_poly: 0.2877326671559647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Создаем объект PolynomialFeatures для добавления попарных произведений и квадратов признаков\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "# Масштабируем данные\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "# Добавляем попарные произведения и квадраты признаков\n",
    "X_train_poly = poly.fit_transform(X_train_standard_scaled)\n",
    "X_test_poly = poly.transform(X_test_standard_scaled)\n",
    "\n",
    "# Масштабируем признаки с помощью StandardScaler\n",
    "X_train_scaled = standard_scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = standard_scaler.transform(X_test_poly)\n",
    "\n",
    "# Обучаем модель Ridge с параметрами по умолчанию\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "r2_ridge_standart_scaler_poly = ridge.score(X_test_scaled, y_test)\n",
    "print(f'r2_ridge_standart_scaler_poly: {r2_ridge_standart_scaler_poly}')\n",
    "\n",
    "# Обучаем модель Lasso с параметрами по умолчанию\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "r2_lasso_standart_scaler_poly = lasso.score(X_test_scaled, y_test)\n",
    "print(f'r2_lasso_standart_scaler_poly: {r2_lasso_standart_scaler_poly}')\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "# Масштабируем данные MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_min_max_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Добавляем попарные произведения и квадраты признаков\n",
    "X_train_poly = poly.fit_transform(X_train_min_max_scaled)\n",
    "X_test_poly = poly.transform(X_test_min_max_scaled)\n",
    "\n",
    "# Масштабируем признаки с помощью StandardScaler\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = min_max_scaler.transform(X_test_poly)\n",
    "\n",
    "# Обучаем модель Ridge с параметрами по умолчанию\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "r2_ridge_min_max_scaler_poly = ridge.score(X_test_scaled, y_test)\n",
    "print(f'r2_ridge_min_max_scaler_poly: {r2_ridge_min_max_scaler_poly}')\n",
    "\n",
    "# Обучаем модель Lasso с параметрами по умолчанию\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "r2_lasso_min_max_scaler_poly = lasso.score(X_test_scaled, y_test)\n",
    "print(f'r2_lasso_min_max_scaler_poly: {r2_lasso_min_max_scaler_poly}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Метрика R2 улучшилась после добавления попарных произведений и квадратов признаков для обеих моделей.\n",
    "\n",
    "r2_ridge_standart_scaler_poly: 0.8172321234956247\n",
    "r2_lasso_standart_scaler_poly: 0.7388607450771216\n",
    "------\n",
    "r2_ridge_min_max_scaler_poly: 0.8309016090915325\n",
    "r2_lasso_min_max_scaler_poly: 0.7319986508747183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создаем пайплайн для масштабирования, генерации полиномиальных признаков и моделирования\n",
    "pipe_standard_scaler = make_pipeline(StandardScaler(), PolynomialFeatures())\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Масштабируем данные\n",
    "X_train_standard_scaled = pipe_standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = pipe_standard_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_standard_scaled, y_train)\n",
    "lasso_cv.fit(X_train_standard_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_standart_scaler_poly_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_standart_scaler_poly_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV StandardScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV StandardScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(f'r2_ridge_standart_scaler_poly_cv: {r2_ridge_standart_scaler_poly_cv}')\n",
    "print(f'r2_lasso_standart_scaler_poly_cv: {r2_lasso_standart_scaler_poly_cv}')\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "pipe_min_max_scaler = make_pipeline(MinMaxScaler(), PolynomialFeatures())\n",
    "X_train_min_max_scaled = pipe_min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = pipe_min_max_scaler.transform(X_test)\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "ridge_cv.fit(X_train_min_max_scaled, y_train)\n",
    "lasso_cv.fit(X_test_min_max_scaled, y_train)\n",
    "r2_ridge_min_max_scaler_poly_cv = ridge_cv.score(X_test_min_max_scaled, y_test)\n",
    "r2_lasso_min_max_scaler_poly_cv = lasso_cv.score(X_test_min_max_scaled, y_test)\n",
    "print(\"Ridge RidgeCV MinMaxScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV MinMaxScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "print(f'r2_ridge_min_max_scaler_poly_cv: {r2_ridge_min_max_scaler_poly_cv}')\n",
    "print(f'r2_lasso_min_max_scaler_poly_cv: {r2_lasso_min_max_scaler_poly_cv}')\n",
    "\n",
    "\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'poly__degree': 3, 'reg': Ridge(alpha=0.1), 'reg__alpha': 0.1, 'scaler': MinMaxScaler()}\n",
      "r2_best_model 0.86624814908432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создаем Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('poly', PolynomialFeatures()), \n",
    "    ('reg', Ridge())\n",
    "])\n",
    "\n",
    "# Создаем сетку параметров, которые будем перебирать в GridSearchCV\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],  # Степень полинома\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],  # Метод масштабирования\n",
    "    'reg': [Ridge(), Lasso()],  # Тип регуляризации\n",
    "    'reg__alpha': [0.1, 1, 10]  # Коэффициент регуляризации\n",
    "}\n",
    "\n",
    "# Создаем GridSearchCV с заданными параметрами\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Обучаем модель и выводим лучшие параметры и результат R2\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Параметры лучшей модели:\\n', grid.best_params_)\n",
    "r2_best_model = grid.best_score_\n",
    "print('r2_best_model', r2_best_model)\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.665961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.666869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.668190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>-20.660347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.668482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>-21.108988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.817232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.840244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lasso_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.738861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.287733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best_Model</td>\n",
       "      <td>task8</td>\n",
       "      <td>0.866248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model   task         R2\n",
       "0                          LR  task2   0.668483\n",
       "1                       Ridge  task2   0.665961\n",
       "2                       Lasso  task2   0.666869\n",
       "3          Ridge_GridSearchCV  task3   0.668483\n",
       "4                     RidgeCV  task3   0.668483\n",
       "5          Lasso_GridSearchCV  task3   0.668483\n",
       "6                     LassoCV  task3   0.668483\n",
       "11    Ridge_StandardScaler_CV  task5   0.668190\n",
       "12      Ridge_MinMaxScaler_CV  task5 -20.660347\n",
       "13    Lasso_StandardScaler_CV  task5   0.668482\n",
       "14      Lasso_MinMaxScaler_CV  task5 -21.108988\n",
       "15  Ridge_StandardScaler_Poly  task6   0.817232\n",
       "16    Ridge_MinMaxScaler_Poly  task6   0.840244\n",
       "17  Lasso_StandardScaler_Poly  task6   0.738861\n",
       "18    Lasso_MinMaxScaler_Poly  task6   0.287733\n",
       "23                 Best_Model  task8   0.866248"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64                 ?  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                  ?  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  class  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3      United-States  <=50K  \n",
       "4               Cuba  <=50K  \n",
       "...              ...    ...  \n",
       "48837  United-States  <=50K  \n",
       "48838  United-States  <=50K  \n",
       "48839  United-States  <=50K  \n",
       "48840  United-States  <=50K  \n",
       "48841  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Замена целевой переменной на числовые значения\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выделение признаков и целевой переменной\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_most_frequent: 0.7581382652016652\n",
      "f1_most_frequent: 0.8624330409129726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# предсказание самого частого класса\n",
    "y_pred = np.zeros_like(y_test) + y_train.value_counts().idxmax()\n",
    "\n",
    "# y_test - истинные значения целевой переменной на тестовой выборке\n",
    "# y_pred - предсказанные значения\n",
    "\n",
    "acc_most_frequent = accuracy_score(y_test, y_pred)\n",
    "f1_most_frequent = f1_score(y_test, y_pred)\n",
    "print(f\"acc_most_frequent: {acc_most_frequent}\")\n",
    "print(f\"f1_most_frequent: {f1_most_frequent}\")\n",
    "\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 'State-gov', 77516, ..., 0, 40, 'United-States'],\n",
       "       [50, 'Self-emp-not-inc', 83311, ..., 0, 13, 'United-States'],\n",
       "       [38, 'Private', 215646, ..., 0, 40, 'United-States'],\n",
       "       ...,\n",
       "       [38, 'Private', 374983, ..., 0, 50, 'United-States'],\n",
       "       [44, 'Private', 83891, ..., 0, 40, 'United-States'],\n",
       "       [35, 'Self-emp-inc', 182148, ..., 0, 60, 'United-States']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# X = X.replace(\"?\", np.NaN)\n",
    "# Создаем объект класса SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Применяем imputer к датафрейму X\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_columns: ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "categorical_columns: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "print(f\"numerical_columns: {num_cols}\")\n",
    "print(f\"categorical_columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cross_val_score - это функция из библиотеки scikit-learn в Python, которая позволяет оценить качество работы модели с использованием кросс-валидации.\n",
    "Кросс-валидация - это процедура, при которой исходный набор данных разбивается на k равных частей. Затем k раз модель обучается на k-1 частей и тестируется на оставшейся части. Результаты тестирования усредняются для получения итоговой метрики качества.\n",
    "cross_val_score принимает на вход модель, данные и метки классов, а также параметры кросс-валидации, такие как число разбиений, и метрику, на основе которой будет проводиться оценка качества модели. Функция возвращает массив значений метрики качества модели для каждого разбиения."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OneHotEncoder принимает на вход массив категориальных признаков и создает матрицу бинарных признаков, где каждый столбец соответствует одному уникальному значению категориального признака. Если у нас есть n уникальных значений категориального признака, то метод создаст n новых бинарных признаков. Если значение категориального признака соответствует определенному столбцу в матрице бинарных признаков, то значение в этом столбце будет равно 1, во всех остальных столбцах - 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_LR: 0.8508252089273688\n",
      "acc_KNN: 0.8247409969643567\n",
      "acc_SVM: 0.8529135478362626\n",
      "f1_LR: 0.9047857586982012\n",
      "f1_KNN: 0.8869692965663359\n",
      "f1_SVM: 0.9063223083526415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Пайплайн для обработки числовых признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Пайплайн для обработки категориальных признаков\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединяем числовой и категориальный пайплайны\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Define pipeline with column transformer and classifiers\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svc)\n",
    "])\n",
    "\n",
    "# Calculate cross-validation scores using accuracy and F1 metrics\n",
    "acc_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "print(f\"acc_LR: {acc_LR}\")\n",
    "print(f\"acc_KNN: {acc_KNN}\")\n",
    "print(f\"acc_SVM: {acc_SVM}\")\n",
    "\n",
    "print(f\"f1_LR: {f1_LR}\")\n",
    "print(f\"f1_KNN: {f1_KNN}\")\n",
    "print(f\"f1_SVM: {f1_SVM}\")\n",
    "                                           \n",
    "                                           \n",
    "results_classification.loc[1] = ['LogisticRegression', 'task13', f1_LR, acc_LR]\n",
    "results_classification.loc[2] = ['KNeighborsClassifier', 'task13', f1_KNN, acc_KNN]\n",
    "results_classification.loc[3] = ['LinearSVC', 'task13', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_LR: 0.8508252089273688\n",
    "acc_KNN: 0.8247409969643567\n",
    "acc_SVM: 0.8529135478362626\n",
    "f1_LR: 0.9047857586982012\n",
    "f1_KNN: 0.8869692965663359\n",
    "f1_SVM: 0.9063223083526415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_LR: 0.8507023483249301\n",
      "acc_KNN: 0.8252118868046804\n",
      "acc_SVM: 0.8512551277675652\n",
      "f1_LR: 0.9047791034209263\n",
      "f1_KNN: 0.8873196076146141\n",
      "f1_SVM: 0.9054218744827377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "# Пайплайн для обработки числовых признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Пайплайн для обработки категориальных признаков\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединяем числовой и категориальный пайплайны\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Define pipeline with column transformer and classifiers\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svc)\n",
    "])\n",
    "\n",
    "# Calculate cross-validation scores using accuracy and F1 metrics\n",
    "acc_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "print(f\"acc_LR: {acc_LR}\")\n",
    "print(f\"acc_KNN: {acc_KNN}\")\n",
    "print(f\"acc_SVM: {acc_SVM}\")\n",
    "\n",
    "print(f\"f1_LR: {f1_LR}\")\n",
    "print(f\"f1_KNN: {f1_KNN}\")\n",
    "print(f\"f1_SVM: {f1_SVM}\")\n",
    "                                           \n",
    "                                           \n",
    "results_classification.loc[4] = ['LogisticRegression_impute', 'task14', f1_LR, acc_LR]\n",
    "results_classification.loc[5] = ['KNeighborsClassifier_impute', 'task14', f1_KNN, acc_KNN]\n",
    "results_classification.loc[6] = ['LinearSVC_impute', 'task14', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_LR: 0.8507023483249301\n",
    "acc_KNN: 0.8252118868046804\n",
    "acc_SVM: 0.8512551277675652\n",
    "f1_LR: 0.9047791034209263\n",
    "f1_KNN: 0.8873196076146141\n",
    "f1_SVM: 0.9054218744827377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_LR_del_missings: 0.8467339991770471\n",
      "acc_KNN_del_missings: 0.8205298095497255\n",
      "acc_SVM_del_missings: 0.8485030154158197\n",
      "f1_LR_del_missings: 0.9010789016007372\n",
      "f1_KNN_del_missings: 0.8829256825024464\n",
      "f1_SVM_del_missings: 0.9024033119235104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.dropna()\n",
    "# data.mask(data.eq('?')).dropna()\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Пайплайн для обработки числовых признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Пайплайн для обработки категориальных признаков\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединяем числовой и категориальный пайплайны\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Define pipeline with column transformer and classifiers\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', svc)\n",
    "])\n",
    "\n",
    "# Calculate cross-validation scores using accuracy and F1 metrics\n",
    "acc_LR_del_missings = cross_val_score(pipe_lr, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_LR_del_missings = cross_val_score(pipe_lr, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_KNN_del_missings = cross_val_score(pipe_knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_KNN_del_missings = cross_val_score(pipe_knn, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_SVM_del_missings = cross_val_score(pipe_svc, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_SVM_del_missings = cross_val_score(pipe_svc, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "print(f\"acc_LR_del_missings: {acc_LR_del_missings}\")\n",
    "print(f\"acc_KNN_del_missings: {acc_KNN_del_missings}\")\n",
    "print(f\"acc_SVM_del_missings: {acc_SVM_del_missings}\")\n",
    "\n",
    "print(f\"f1_LR_del_missings: {f1_LR_del_missings}\")\n",
    "print(f\"f1_KNN_del_missings: {f1_KNN_del_missings}\")\n",
    "print(f\"f1_SVM_del_missings: {f1_SVM_del_missings}\")\n",
    "\n",
    "\n",
    "results_classification.loc[7] = ['LogisticRegression_delete_missings', 'task15', f1_LR_del_missings, acc_LR_del_missings]\n",
    "results_classification.loc[8] = ['KNeighborsClassifier_delete_missings', 'task15', f1_KNN_del_missings, acc_KNN_del_missings]\n",
    "results_classification.loc[9] = ['LinearSVC_delete_missings', 'task15', f1_SVM_del_missings, acc_SVM_del_missings]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_LR_del_missings: 0.8467339991770471\n",
    "acc_KNN_del_missings: 0.8205298095497255\n",
    "acc_SVM_del_missings: 0.8485030154158197\n",
    "f1_LR_del_missings: 0.9010789016007372\n",
    "f1_KNN_del_missings: 0.8829256825024464\n",
    "f1_SVM_del_missings: 0.9024033119235104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_RF: 0.8514394113355113\n",
      "acc_GB: 0.8665903354382216\n",
      "f1_RF: 0.9040587148361044\n",
      "f1_GB: 0.9155015819476015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "# Пайплайн для обработки числовых признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Пайплайн для обработки категориальных признаков\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединяем числовой и категориальный пайплайны\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "# Define classifiers\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Define pipeline with column transformer and classifiers\n",
    "pipe_rfc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rfc)\n",
    "])\n",
    "\n",
    "pipe_gbc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gbc)\n",
    "])\n",
    "\n",
    "\n",
    "# Calculate cross-validation scores using accuracy and F1 metrics\n",
    "acc_RF = cross_val_score(pipe_rfc, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_RF = cross_val_score(pipe_rfc, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "acc_GB = cross_val_score(pipe_gbc, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_GB = cross_val_score(pipe_gbc, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "\n",
    "print(f\"acc_RF: {acc_RF}\")\n",
    "print(f\"acc_GB: {acc_GB}\")\n",
    "\n",
    "print(f\"f1_RF: {f1_RF}\")\n",
    "print(f\"f1_GB: {f1_GB}\")\n",
    "\n",
    "results_classification.loc[10] = ['RandomForestClassifier', 'task16', f1_RF, acc_RF]\n",
    "results_classification.loc[11] = ['GradientBoostingClassifier', 'task16', f1_GB, acc_GB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_RF: 0.8514394113355113\n",
    "acc_GB: 0.8665903354382216\n",
    "f1_RF: 0.9040587148361044\n",
    "f1_GB: 0.9155015819476015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Определение шагов для обработки числовых и категориальных признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение шагов в пайплайн\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Определение классификаторов\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "# Определение пайплайна\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', classifiers)])\n",
    "\n",
    "# Определение сетки параметров для подбора\n",
    "param_grid = [\n",
    "    {\n",
    "        'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "        'classifier': classifiers\n",
    "    },\n",
    "    {\n",
    "        'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "        'preprocessor__cat__onehot__handle_unknown': ['error', 'ignore'],\n",
    "        'classifier': classifiers\n",
    "    }\n",
    "]\n",
    "\n",
    "# Подбор наилучшей модели\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Вывод результатов\n",
    "acc_best = grid_search.best_score_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "\n",
    "results_classification.loc[12] = ['Best_Model', 'task17', f1_best, acc_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Most Frequent class</td>\n",
       "      <td>task10</td>\n",
       "      <td>0.862433</td>\n",
       "      <td>0.758138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>task13</td>\n",
       "      <td>0.904786</td>\n",
       "      <td>0.850825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>task13</td>\n",
       "      <td>0.886969</td>\n",
       "      <td>0.824741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>task13</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>0.852914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression_delete_missings</td>\n",
       "      <td>task15</td>\n",
       "      <td>0.901079</td>\n",
       "      <td>0.846734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier_delete_missings</td>\n",
       "      <td>task15</td>\n",
       "      <td>0.882926</td>\n",
       "      <td>0.82053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC_delete_missings</td>\n",
       "      <td>task15</td>\n",
       "      <td>0.902403</td>\n",
       "      <td>0.848503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_impute</td>\n",
       "      <td>task14</td>\n",
       "      <td>0.904779</td>\n",
       "      <td>0.850702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier_impute</td>\n",
       "      <td>task14</td>\n",
       "      <td>0.88732</td>\n",
       "      <td>0.825212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC_impute</td>\n",
       "      <td>task14</td>\n",
       "      <td>0.905422</td>\n",
       "      <td>0.851255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>task16</td>\n",
       "      <td>0.904059</td>\n",
       "      <td>0.851439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>task16</td>\n",
       "      <td>0.915502</td>\n",
       "      <td>0.86659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model    task        f1  accuracy\n",
       "0                    Most Frequent class  task10  0.862433  0.758138\n",
       "1                     LogisticRegression  task13  0.904786  0.850825\n",
       "2                   KNeighborsClassifier  task13  0.886969  0.824741\n",
       "3                              LinearSVC  task13  0.906322  0.852914\n",
       "7     LogisticRegression_delete_missings  task15  0.901079  0.846734\n",
       "8   KNeighborsClassifier_delete_missings  task15  0.882926   0.82053\n",
       "9              LinearSVC_delete_missings  task15  0.902403  0.848503\n",
       "4              LogisticRegression_impute  task14  0.904779  0.850702\n",
       "5            KNeighborsClassifier_impute  task14   0.88732  0.825212\n",
       "6                       LinearSVC_impute  task14  0.905422  0.851255\n",
       "10                RandomForestClassifier  task16  0.904059  0.851439\n",
       "11            GradientBoostingClassifier  task16  0.915502   0.86659"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
