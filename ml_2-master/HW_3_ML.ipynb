{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R2 - это коэффициент детерминации, который используется для оценки качества подгонки регрессионной модели к данным. Это мера, которая показывает, как хорошо модель подходит к данным и объясняет их вариацию.\n",
    "\n",
    "Значение R2 находится в диапазоне от 0 до 1, где 0 означает, что модель не объясняет никакой вариации в данных, а 1 означает, что модель объясняет всю вариацию в данных. Чем ближе значение R2 к 1, тем лучше модель подходит к данным.\n",
    "\n",
    "L1 регуляризация Lasso (Least Absolute Shrinkage and Selection Operator) - это метод регрессии, который применяет регуляризацию Лассо. Регуляризация Лассо добавляет к функции потерь (обычно среднеквадратическая ошибка) сумму модулей коэффициентов регрессии. Это приводит к уменьшению веса некоторых признаков до нуля, что позволяет производить отбор признаков и упрощать модель. В отличие от регрессии Ridge, где веса признаков стремятся к нулю, но не доходят до него, в регуляризации Лассо некоторые веса могут быть точно равны нулю.\n",
    "\n",
    "L1 регуляризация обнуляет веса, это можно использовать для прореживания модели.\n",
    "Для чего это нужно:\n",
    "• ускорение модели\n",
    "• мы знаем что есть лишние признаки(линейно зависимые, шумные)\n",
    "• данных меньше чем признаков\n",
    "\n",
    "Метод Ridge заключается в добавлении L2 регуляризации к обычной линейной регрессии, что помогает снизить влияние высоко коррелированных признаков на модель. L2 регуляризация заключается в добавлении штрафа на величину коэффициентов регрессии (кроме константы), что приводит к уменьшению их значений и позволяет уменьшить переобучение модели. Параметр регуляризации alpha в Ridge регрессии позволяет управлять силой регуляризации и выбирать оптимальное значение, чтобы достичь наилучшей производительности модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression R2 score: 0.668482575397159\n",
      "Ridge regression R2 score: 0.6659608075261695\n",
      "Lasso regression R2 score: 0.6668687223368214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "r2_lr = lr.score(X_test, y_test)\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "r2_ridge = ridge.score(X_test, y_test)\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "r2_lasso = lasso.score(X_test, y_test)\n",
    "\n",
    "print(f\"Linear regression R2 score: {r2_lr}\")\n",
    "print(f\"Ridge regression R2 score: {r2_ridge}\")\n",
    "print(f\"Lasso regression R2 score: {r2_lasso}\")\n",
    "\n",
    "\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GridSearchCV - это метод подбора наилучших параметров модели, основанный на переборе всех возможных комбинаций параметров и выборе тех, которые дают наилучший результат.\n",
    "\n",
    "RidgeCV и LassoCV - это модификации Ridge и Lasso моделей, которые автоматически подбирают коэффициент регуляризации на основе кросс-валидаци"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge GridSearchCV : Best alpha = 1e-05\n",
      "Lasso GridSearchCV: Best alpha = 1e-05\n",
      "Ridge RidgeCV: Best alpha = 1e-05\n",
      "Lasso LassoCV: Best alpha = 1e-05\n",
      "r2_ridge: 0.6659608075261695\n",
      "r2_ridge_grid_search: 0.6684825680074258\n",
      "r2_ridge_cv: 0.6684825680074258\n",
      "------\n",
      "r2_lasso: 0.6668687223368214\n",
      "r2_lasso_grid_search: 0.668482959588568\n",
      "r2_lasso_cv: 0.668482959588568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Создаем объект модели\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "# Создаем сетку параметров для перебора\n",
    "param_grid = {'alpha': [10**i for i in range(-5, 6)]}\n",
    "\n",
    "# Инициализируем объект GridSearchCV\n",
    "ridge_grid_search_cv = GridSearchCV(ridge, param_grid, cv=5)\n",
    "lasso_grid_search_cv = GridSearchCV(lasso, param_grid, cv=5)\n",
    "\n",
    "# Обучаем модели на обучающей выборке\n",
    "ridge_grid_search_cv.fit(X_train, y_train)\n",
    "lasso_grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_grid_search = ridge_grid_search_cv.score(X_test, y_test)\n",
    "r2_lasso_grid_search = lasso_grid_search_cv.score(X_test, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge GridSearchCV : Best alpha =\", ridge_grid_search_cv.best_params_['alpha'])\n",
    "print(\"Lasso GridSearchCV: Best alpha =\", lasso_grid_search_cv.best_params_['alpha'])\n",
    "\n",
    "\n",
    "# Инициализируем объекты RidgeCV и LassoCV\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Обучаем модели на обучающей выборке\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_cv = ridge_cv.score(X_test, y_test)\n",
    "r2_lasso_cv = lasso_cv.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "\n",
    "print(f\"r2_ridge: {r2_ridge}\")\n",
    "print(f\"r2_ridge_grid_search: {r2_ridge_grid_search}\")\n",
    "print(f\"r2_ridge_cv: {r2_ridge_cv}\")\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(f\"r2_lasso: {r2_lasso}\")\n",
    "print(f\"r2_lasso_grid_search: {r2_lasso_grid_search}\")\n",
    "print(f\"r2_lasso_cv: {r2_lasso_cv}\")\n",
    "\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_ridge: 0.6659608075261695\n",
      "r2_ridge_grid_search: 0.6684825680074258\n",
      "r2_ridge_cv: 0.6684825680074258\n",
      "r2_ridge_standart_scaler: 0.668190107677443\n",
      "r2_ridge_min_max_scaler: 0.6762207658974593\n",
      "------\n",
      "r2_lasso: 0.6668687223368214\n",
      "r2_lasso_grid_search: 0.668482959588568\n",
      "r2_lasso_cv: 0.668482959588568\n",
      "r2_lasso_standart_scaler: 0.624044752347846\n",
      "r2_lasso_min_max_scaler: 0.2573921442545195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Создаем Pipeline для масштабирования данных и обучения Ridge/Lasso модели\n",
    "pipeline_ridge_standard_scaler = Pipeline([('scaler', StandardScaler()), ('reg', Ridge())])\n",
    "pipeline_lasso_standard_scaler = Pipeline([('scaler', StandardScaler()), ('reg', Lasso())])\n",
    "\n",
    "# Обучаем модели\n",
    "pipeline_ridge_standard_scaler.fit(X_train, y_train)\n",
    "pipeline_lasso_standard_scaler.fit(X_train, y_train)\n",
    "\n",
    "# Вычисляем R2 на тестовой выборке\n",
    "y_predict_ridge_standard_scaler = pipeline_ridge_standard_scaler.predict(X_test)\n",
    "y_predict_lasso_standard_scaler = pipeline_lasso_standard_scaler.predict(X_test)\n",
    "\n",
    "r2_ridge_standart_scaler = r2_score(y_test, y_predict_ridge_standard_scaler)\n",
    "r2_lasso_standart_scaler = r2_score(y_test, y_predict_lasso_standard_scaler)\n",
    "\n",
    "\n",
    "# Создаем Pipeline с MinMaxScaler и Ridge/Lasso\n",
    "pipeline_ridge_min_max_scaler = Pipeline([('scaler', MinMaxScaler()), ('reg', Ridge())])\n",
    "pipeline_lasso_min_max_scaler = Pipeline([('scaler', MinMaxScaler()), ('reg', Lasso())])\n",
    "\n",
    "\n",
    "# Обучаем модели\n",
    "pipeline_ridge_min_max_scaler.fit(X_train, y_train)\n",
    "pipeline_lasso_min_max_scaler.fit(X_train, y_train)\n",
    "\n",
    "# Вычисляем R2 на тестовой выборке\n",
    "y_predict_ridge_min_max_scaler = pipeline_ridge_min_max_scaler.predict(X_test)\n",
    "y_predict_lasso_min_max_scaler = pipeline_lasso_min_max_scaler.predict(X_test)\n",
    "r2_ridge_min_max_scaler = r2_score(y_test, y_predict_ridge_min_max_scaler)\n",
    "r2_lasso_min_max_scaler = r2_score(y_test, y_predict_lasso_min_max_scaler)\n",
    "\n",
    "\n",
    "print(f\"r2_ridge: {r2_ridge}\")\n",
    "print(f\"r2_ridge_grid_search: {r2_ridge_grid_search}\")\n",
    "print(f\"r2_ridge_cv: {r2_ridge_cv}\")\n",
    "print(f\"r2_ridge_standart_scaler: {r2_ridge_standart_scaler}\")\n",
    "print(f\"r2_ridge_min_max_scaler: {r2_ridge_min_max_scaler}\")\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(f\"r2_lasso: {r2_lasso}\")\n",
    "print(f\"r2_lasso_grid_search: {r2_lasso_grid_search}\")\n",
    "print(f\"r2_lasso_cv: {r2_lasso_cv}\")\n",
    "print(f\"r2_lasso_standart_scaler: {r2_lasso_standart_scaler}\")\n",
    "print(f\"r2_lasso_min_max_scaler: {r2_lasso_min_max_scaler}\")\n",
    "\n",
    "\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RidgeCV StandardScaler: Best alpha = 1.0\n",
      "Lasso LassoCV StandardScaler: Best alpha = 1e-05\n",
      "r2_ridge_standart_scaler_cv:  0.6681901076774431\n",
      "r2_lasso_standart_scaler_cv:  0.6684821312777706\n",
      "------\n",
      "Ridge RidgeCV MinMaxScaler: Best alpha = 0.1\n",
      "Lasso LassoCV MinMaxScaler: Best alpha = 1e-05\n",
      "r2_ridge_min_max_scaler_cv:  -20.660347184502935\n",
      "r2_lasso_min_max_scaler_cv:  -21.108987672687494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Создаем объекты RidgeCV и LassoCV\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Масштабируем данные\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_standard_scaled, y_train)\n",
    "lasso_cv.fit(X_train_standard_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_standart_scaler_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_standart_scaler_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV StandardScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV StandardScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(\"r2_ridge_standart_scaler_cv: \", r2_ridge_standart_scaler_cv)\n",
    "print(\"r2_lasso_standart_scaler_cv: \", r2_lasso_standart_scaler_cv)\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "# Масштабируем данные\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_min_max_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_min_max_scaled, y_train)\n",
    "lasso_cv.fit(X_train_min_max_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_min_max_scaler_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_min_max_scaler_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV MinMaxScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV MinMaxScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(\"r2_ridge_min_max_scaler_cv: \", r2_ridge_min_max_scaler_cv)\n",
    "print(\"r2_lasso_min_max_scaler_cv: \", r2_lasso_min_max_scaler_cv)\n",
    "\n",
    "\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_ridge_standart_scaler_poly: 0.8172321234956248\n",
      "r2_lasso_standart_scaler_poly: 0.7388607450771216\n",
      "------\n",
      "r2_ridge_min_max_scaler_poly: 0.8309016090915333\n",
      "r2_lasso_min_max_scaler_poly: 0.7319986508747183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Создаем объект PolynomialFeatures для добавления попарных произведений и квадратов признаков\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "\n",
    "# Масштабируем данные\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "# Добавляем попарные произведения и квадраты признаков\n",
    "X_train_poly = poly.fit_transform(X_train_standard_scaled)\n",
    "X_test_poly = poly.transform(X_test_standard_scaled)\n",
    "\n",
    "# Масштабируем признаки с помощью StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Обучаем модель Ridge с параметрами по умолчанию\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "r2_ridge_standart_scaler_poly = ridge.score(X_test_scaled, y_test)\n",
    "print(f'r2_ridge_standart_scaler_poly: {r2_ridge_standart_scaler_poly}')\n",
    "\n",
    "# Обучаем модель Lasso с параметрами по умолчанию\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "r2_lasso_standart_scaler_poly = lasso.score(X_test_scaled, y_test)\n",
    "print(f'r2_lasso_standart_scaler_poly: {r2_lasso_standart_scaler_poly}')\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "# Масштабируем данные MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_min_max_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Добавляем попарные произведения и квадраты признаков\n",
    "X_train_poly = poly.fit_transform(X_train_min_max_scaled)\n",
    "X_test_poly = poly.transform(X_test_min_max_scaled)\n",
    "\n",
    "# Масштабируем признаки с помощью StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Обучаем модель Ridge с параметрами по умолчанию\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "r2_ridge_min_max_scaler_poly = ridge.score(X_test_scaled, y_test)\n",
    "print(f'r2_ridge_min_max_scaler_poly: {r2_ridge_min_max_scaler_poly}')\n",
    "\n",
    "# Обучаем модель Lasso с параметрами по умолчанию\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "r2_lasso_min_max_scaler_poly = lasso.score(X_test_scaled, y_test)\n",
    "print(f'r2_lasso_min_max_scaler_poly: {r2_lasso_min_max_scaler_poly}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Метрика R2 улучшилась после добавления попарных произведений и квадратов признаков для обеих моделей.\n",
    "\n",
    "r2_ridge_standart_scaler_poly: 0.8172321234956247\n",
    "r2_lasso_standart_scaler_poly: 0.7388607450771216\n",
    "------\n",
    "r2_ridge_min_max_scaler_poly: 0.8309016090915325\n",
    "r2_lasso_min_max_scaler_poly: 0.7319986508747183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.708888102574747, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325.3702094752035, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 649.714807377882, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 701.103275331969, tolerance: 2.8821090464396293\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.920691500992689, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 631.2541944140235, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 688.2257797689585, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 706.3452020994636, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.578920016725988, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 460.04938860282766, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 780.005252980808, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 796.3896345455089, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2393902382164015, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 496.0011949605929, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 722.36951992474, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 737.2028617831579, tolerance: 2.729756922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.469413744865051, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 658.7587301766123, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 760.0448473171214, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 767.9086952605459, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RidgeCV StandardScaler: Best alpha = 10.0\n",
      "Lasso LassoCV StandardScaler: Best alpha = 0.1\n",
      "r2_ridge_standart_scaler_poly_cv: 0.8187344606117982\n",
      "r2_lasso_standart_scaler_poly_cv: 0.8128138856150267\n",
      "------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X and y have inconsistent dimensions (102 != 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-3e23fd1142b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mlasso_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mridge_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_min_max_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mlasso_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_min_max_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mr2_ridge_min_max_scaler_poly_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_min_max_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mr2_lasso_min_max_scaler_poly_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_min_max_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             raise ValueError(\"X and y have inconsistent dimensions (%d != %d)\"\n\u001b[0m\u001b[0;32m   1252\u001b[0m                              % (X.shape[0], y.shape[0]))\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X and y have inconsistent dimensions (102 != 404)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создаем пайплайн для масштабирования, генерации полиномиальных признаков и моделирования\n",
    "pipe_standard_scaler = make_pipeline(StandardScaler(), PolynomialFeatures())\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "\n",
    "# Масштабируем данные\n",
    "X_train_standard_scaled = pipe_standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = pipe_standard_scaler.transform(X_test)\n",
    "\n",
    "# Обучаем модели на масштабированных данных\n",
    "ridge_cv.fit(X_train_standard_scaled, y_train)\n",
    "lasso_cv.fit(X_train_standard_scaled, y_train)\n",
    "\n",
    "# Получаем значения R2 для Ridge и Lasso на тестовой выборке\n",
    "r2_ridge_standart_scaler_poly_cv = ridge_cv.score(X_test_standard_scaled, y_test)\n",
    "r2_lasso_standart_scaler_poly_cv = lasso_cv.score(X_test_standard_scaled, y_test)\n",
    "\n",
    "# Выводим наилучшие параметры и R2 на тестовой выборке\n",
    "print(\"Ridge RidgeCV StandardScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV StandardScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "\n",
    "# Выводим значения R2\n",
    "print(f'r2_ridge_standart_scaler_poly_cv: {r2_ridge_standart_scaler_poly_cv}')\n",
    "print(f'r2_lasso_standart_scaler_poly_cv: {r2_lasso_standart_scaler_poly_cv}')\n",
    "print(\"------\")\n",
    "\n",
    "\n",
    "pipe_min_max_scaler = make_pipeline(MinMaxScaler(), PolynomialFeatures())\n",
    "X_train_min_max_scaled = pipe_min_max_scaler.fit_transform(X_train)\n",
    "X_test_min_max_scaled = pipe_min_max_scaler.transform(X_test)\n",
    "ridge_cv = RidgeCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[10**i for i in range(-5, 6)], cv=5)\n",
    "ridge_cv.fit(X_train_min_max_scaled, y_train)\n",
    "lasso_cv.fit(X_test_min_max_scaled, y_train)\n",
    "r2_ridge_min_max_scaler_poly_cv = ridge_cv.score(X_test_min_max_scaled, y_test)\n",
    "r2_lasso_min_max_scaler_poly_cv = lasso_cv.score(X_test_min_max_scaled, y_test)\n",
    "print(\"Ridge RidgeCV MinMaxScaler: Best alpha =\", ridge_cv.alpha_)\n",
    "print(\"Lasso LassoCV MinMaxScaler: Best alpha =\", lasso_cv.alpha_)\n",
    "print(f'r2_ridge_min_max_scaler_poly_cv: {r2_ridge_min_max_scaler_poly_cv}')\n",
    "print(f'r2_lasso_min_max_scaler_poly_cv: {r2_lasso_min_max_scaler_poly_cv}')\n",
    "\n",
    "\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'poly__degree': 3, 'reg': Ridge(alpha=0.1), 'reg__alpha': 0.1, 'scaler': MinMaxScaler()}\n",
      "r2_best_model 0.8662481490843126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создаем Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('poly', PolynomialFeatures()), \n",
    "    ('reg', Ridge())\n",
    "])\n",
    "\n",
    "# Создаем сетку параметров, которые будем перебирать в GridSearchCV\n",
    "param_grid = {\n",
    "    'poly__degree': [1, 2, 3],  # Степень полинома\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],  # Метод масштабирования\n",
    "    'reg': [Ridge(), Lasso()],  # Тип регуляризации\n",
    "    'reg__alpha': [0.1, 1, 10]  # Коэффициент регуляризации\n",
    "}\n",
    "\n",
    "# Создаем GridSearchCV с заданными параметрами\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Обучаем модель и выводим лучшие параметры и результат R2\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Параметры лучшей модели:\\n', grid.best_params_)\n",
    "r2_best_model = grid.best_score_\n",
    "print('r2_best_model', r2_best_model)\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.665961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.666869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.66819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.676221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.624045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.257392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.66819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>-20.6603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.668482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>-21.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.817232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.830902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lasso_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.738861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.731999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ridge_StandardScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.818734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best_Model</td>\n",
       "      <td>task8</td>\n",
       "      <td>0.866248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model   task        R2\n",
       "0                             LR  task2  0.668483\n",
       "1                          Ridge  task2  0.665961\n",
       "2                          Lasso  task2  0.666869\n",
       "3             Ridge_GridSearchCV  task3  0.668483\n",
       "4                        RidgeCV  task3  0.668483\n",
       "5             Lasso_GridSearchCV  task3  0.668483\n",
       "6                        LassoCV  task3  0.668483\n",
       "7           Ridge_StandardScaler  task4   0.66819\n",
       "8             Ridge_MinMaxScaler  task4  0.676221\n",
       "9           Lasso_StandardScaler  task4  0.624045\n",
       "10            Lasso_MinMaxScaler  task4  0.257392\n",
       "11       Ridge_StandardScaler_CV  task5   0.66819\n",
       "12         Ridge_MinMaxScaler_CV  task5  -20.6603\n",
       "13       Lasso_StandardScaler_CV  task5  0.668482\n",
       "14         Lasso_MinMaxScaler_CV  task5   -21.109\n",
       "15     Ridge_StandardScaler_Poly  task6  0.817232\n",
       "16       Ridge_MinMaxScaler_Poly  task6  0.830902\n",
       "17     Lasso_StandardScaler_Poly  task6  0.738861\n",
       "18       Lasso_MinMaxScaler_Poly  task6  0.731999\n",
       "19  Ridge_StandardScaler_Poly_CV  task7  0.818734\n",
       "23                    Best_Model  task8  0.866248"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64                 ?  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                  ?  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  class  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3      United-States  <=50K  \n",
       "4               Cuba  <=50K  \n",
       "...              ...    ...  \n",
       "48837  United-States  <=50K  \n",
       "48838  United-States  <=50K  \n",
       "48839  United-States  <=50K  \n",
       "48840  United-States  <=50K  \n",
       "48841  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Назначение имен столбцов\n",
    "\n",
    "# Замена целевой переменной на числовые значения\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выделение признаков и целевой переменной\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_most_frequent: 0.7581382652016652\n",
      "f1_most_frequent: 0.8624330409129726\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_classification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-020a4c972f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"f1_most_frequent: {f1_most_frequent}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mresults_classification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Most Frequent class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'task10'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_most_frequent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_most_frequent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_classification' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# предсказание самого частого класса\n",
    "y_pred = np.zeros_like(y_test) + y_train.value_counts().idxmax()\n",
    "\n",
    "# y_test - истинные значения целевой переменной на тестовой выборке\n",
    "# y_pred - предсказанные значения\n",
    "\n",
    "acc_most_frequent = accuracy_score(y_test, y_pred)\n",
    "f1_most_frequent = f1_score(y_test, y_pred)\n",
    "print(f\"acc_most_frequent: {acc_most_frequent}\")\n",
    "print(f\"f1_most_frequent: {f1_most_frequent}\")\n",
    "\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_imputed: [[39 'State-gov' 77516 ... 0 40 'United-States']\n",
      " [50 'Self-emp-not-inc' 83311 ... 0 13 'United-States']\n",
      " [38 'Private' 215646 ... 0 40 'United-States']\n",
      " ...\n",
      " [38 'Private' 374983 ... 0 50 'United-States']\n",
      " [44 'Private' 83891 ... 0 40 'United-States']\n",
      " [35 'Self-emp-inc' 182148 ... 0 60 'United-States']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "print(f\"X_imputed: {X_imputed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_columns: Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week', 'class'],\n",
      "      dtype='object')\n",
      "categorical_columns: Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_columns = data.select_dtypes(include='number').columns\n",
    "\n",
    "categorical_columns = data.select_dtypes(include='object').columns\n",
    "\n",
    "# cat_features = data.select_dtypes(exclude='number')\n",
    "\n",
    "print(f\"numerical_columns: {numerical_columns}\")\n",
    "print(f\"categorical_columns: {categorical_columns}\")\n",
    "# print(f\"cat_features: {cat_features}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cross_val_score - это функция из библиотеки scikit-learn в Python, которая позволяет оценить качество работы модели с использованием кросс-валидации.\n",
    "Кросс-валидация - это процедура, при которой исходный набор данных разбивается на k равных частей. Затем k раз модель обучается на k-1 частей и тестируется на оставшейся части. Результаты тестирования усредняются для получения итоговой метрики качества.\n",
    "cross_val_score принимает на вход модель, данные и метки классов, а также параметры кросс-валидации, такие как число разбиений, и метрику, на основе которой будет проводиться оценка качества модели. Функция возвращает массив значений метрики качества модели для каждого разбиения."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OneHotEncoder принимает на вход массив категориальных признаков и создает матрицу бинарных признаков, где каждый столбец соответствует одному уникальному значению категориального признака. Если у нас есть n уникальных значений категориального признака, то метод создаст n новых бинарных признаков. Если значение категориального признака соответствует определенному столбцу в матрице бинарных признаков, то значение в этом столбце будет равно 1, во всех остальных столбцах - 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler , OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "print(num_cols)\n",
    "print(cat_cols)\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)])\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Define pipeline with column transformer and classifiers\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', lr)\n",
    "])\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', knn)\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', svc)\n",
    "])\n",
    "\n",
    "# Calculate cross-validation scores using accuracy and F1 metrics\n",
    "# acc_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='accuracy')\n",
    "# f1_LR = cross_val_score(pipe_lr, X, y, cv=5, scoring='f1')\n",
    "\n",
    "# acc_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='accuracy')\n",
    "# f1_KNN = cross_val_score(pipe_knn, X, y, cv=5, scoring='f1')\n",
    "\n",
    "# acc_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='accuracy')\n",
    "# f1_SVM = cross_val_score(pipe_svc, X, y, cv=5, scoring='f1')\n",
    "\n",
    "# print(f\"acc_LR: {acc_LR}\")\n",
    "# print(f\"acc_KNN: {acc_KNN}\")\n",
    "# print(f\"acc_SVM: {acc_SVM}\")\n",
    "\n",
    "# print(f\"f1_LR: {f1_LR}\")\n",
    "# print(f\"f1_KNN: {f1_KNN}\")\n",
    "# print(f\"f1_SVM: {f1_SVM}\")\n",
    "                                           \n",
    "                                           \n",
    "# results_classification.loc[1] = ['LogisticRegression', 'task13', f1_LR, acc_LR]\n",
    "# results_classification.loc[2] = ['KNeighborsClassifier', 'task13', f1_KNN, acc_KNN]\n",
    "# results_classification.loc[3] = ['LinearSVC', 'task13', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    37155\n",
       "0    11687\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64                 ?  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                  ?  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  \n",
       "0      United-States  \n",
       "1      United-States  \n",
       "2      United-States  \n",
       "3      United-States  \n",
       "4               Cuba  \n",
       "...              ...  \n",
       "48837  United-States  \n",
       "48838  United-States  \n",
       "48839  United-States  \n",
       "48840  United-States  \n",
       "48841  United-States  \n",
       "\n",
       "[48842 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
       "       'hours-per-week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy scores: [0.84901218 0.84850036 0.85708436 0.85145373 0.8499181 ]\n",
      "LogisticRegression f1 scores: [0.90367661 0.90321737 0.90900795 0.90504548 0.90417048]\n",
      "Mean accuracy: 0.851\n",
      "Mean f1: 0.905\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 512. MiB for an array with shape (134215755,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-eebaea423c72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     pipe = Pipeline(steps=[('preprocessor', preprocessor),\n\u001b[0;32m     36\u001b[0m                            ('model', model)])\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0macc_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mf1_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{model.__class__.__name__} accuracy scores: {acc_scores}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \"\"\"\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    639\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[0;32m    642\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1611\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1612\u001b[1;33m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0m\u001b[0;32m   1613\u001b[0m                                      n_jobs=n_jobs, **kwds)\n\u001b[0;32m   1614\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1773\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1775\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\soft\\Anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 512. MiB for an array with shape (134215755,) and data type int32"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "\n",
    "# Load data and separate target variable\n",
    "data = pd.read_csv('adult.csv')\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, X.select_dtypes(include=['number']).columns),\n",
    "    ('cat', categorical_transformer, X.select_dtypes(include=['object']).columns)])\n",
    "\n",
    "# Define models to evaluate\n",
    "models = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(random_state=42)]\n",
    "\n",
    "# Evaluate models using cross_val_score with accuracy and f1_score metrics\n",
    "for model in models:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "    acc_scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(pipe, X, y, cv=5, scoring='f1')\n",
    "    print(f'{model.__class__.__name__} accuracy scores: {acc_scores}')\n",
    "    print(f'{model.__class__.__name__} f1 scores: {f1_scores}')\n",
    "    print(f'Mean accuracy: {acc_scores.mean():.3f}')\n",
    "    print(f'Mean f1: {f1_scores.mean():.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64                 ?  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                  ?  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  class  \n",
       "0      United-States      1  \n",
       "1      United-States      1  \n",
       "2      United-States      1  \n",
       "3      United-States      1  \n",
       "4               Cuba      1  \n",
       "...              ...    ...  \n",
       "48837  United-States      1  \n",
       "48838  United-States      1  \n",
       "48839  United-States      1  \n",
       "48840  United-States      1  \n",
       "48841  United-States      0  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# Replace '?' with most frequent values\n",
    "data = data.replace('?', pd.Series(data.mode().values.flatten()))\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(['class'], axis=1)\n",
    "y = (data['class'] == '>50K').astype(int)\n",
    "\n",
    "# Define the numerical and categorical transformers\n",
    "num_transformer = make_pipeline(SimpleImputer(strategy='median'), MinMaxScaler())\n",
    "cat_transformer = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "\n",
    "# Use ColumnTransformer to apply the transformers to the correct columns\n",
    "preprocessor = make_column_transformer((num_transformer, X.select_dtypes(include='number').columns),\n",
    "                                       (cat_transformer, X.select_dtypes(include='object').columns))\n",
    "\n",
    "# Create pipelines for LogisticRegression, KNeighborsClassifier, and LinearSVC models\n",
    "lr_pipeline = make_pipeline(preprocessor, LogisticRegression())\n",
    "knn_pipeline = make_pipeline(preprocessor, KNeighborsClassifier())\n",
    "svm_pipeline = make_pipeline(preprocessor, LinearSVC())\n",
    "\n",
    "# Compute cross_val_score using accuracy and f1_score metrics\n",
    "accuracy_lr = cross_val_score(lr_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_lr = cross_val_score(lr_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "accuracy_knn = cross_val_score(knn_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_knn = cross_val_score(knn_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "accuracy_svm = cross_val_score(svm_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "f1_svm = cross_val_score(svm_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "f1_LR = 0\n",
    "acc_LR = 0\n",
    "f1_KNN = 0\n",
    "acc_KNN = 0\n",
    "f1_SVM = 0\n",
    "acc_SVM = 0\n",
    "results_classification.loc[4] = ['LogisticRegression_impute', 'task14', f1_LR, acc_LR]\n",
    "results_classification.loc[5] = ['KNeighborsClassifier_impute', 'task14', f1_KNN, acc_KNN]\n",
    "results_classification.loc[6] = ['LinearSVC_impute', 'task14', f1_SVM, acc_SVM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy - nan, F1 score - nan\n",
      "K-Nearest Neighbors: Accuracy - nan, F1 score - nan\n",
      "Linear SVC: Accuracy - nan, F1 score - nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 336, in fit\n",
      "    return self.partial_fit(X, y)\n",
      "  File \"D:\\soft\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\", line 365, in partial_fit\n",
      "    raise TypeError(\"MinMaxScaler does not support sparse input. \"\n",
      "TypeError: MinMaxScaler does not support sparse input. Consider using MaxAbsScaler instead.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "data = pd.read_csv('adult.csv')\n",
    "data = data.replace('?', np.nan)\n",
    "data = data.dropna()\n",
    "data['class'] = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "\n",
    "num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "print(num_cols)\n",
    "print(cat_cols)\n",
    "\n",
    "\n",
    "preprocessor = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    MinMaxScaler()\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr_pipeline = make_pipeline(preprocessor, LogisticRegression())\n",
    "lr_accuracy = cross_val_score(lr_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "lr_f1 = cross_val_score(lr_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_pipeline = make_pipeline(preprocessor, KNeighborsClassifier())\n",
    "knn_accuracy = cross_val_score(knn_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "knn_f1 = cross_val_score(knn_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "# Linear SVC\n",
    "svc_pipeline = make_pipeline(preprocessor, LinearSVC())\n",
    "svc_accuracy = cross_val_score(svc_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "svc_f1 = cross_val_score(svc_pipeline, X, y, cv=5, scoring='f1').mean()\n",
    "\n",
    "print(\"Logistic Regression: Accuracy - {}, F1 score - {}\".format(lr_accuracy, lr_f1))\n",
    "print(\"K-Nearest Neighbors: Accuracy - {}, F1 score - {}\".format(knn_accuracy, knn_f1))\n",
    "print(\"Linear SVC: Accuracy - {}, F1 score - {}\".format(svc_accuracy, svc_f1))\n",
    "\n",
    "\n",
    "# # выводим результаты\n",
    "# print('Logistic Regression Scores:', lr_scores)\n",
    "# print('KNN Scores:', knn_scores)\n",
    "# print('SVM Scores:', svm_scores)\n",
    "\n",
    "# f1_LR_del_missings = 0\n",
    "# acc_LR_del_missings = 0\n",
    "# f1_KNN_del_missings = 0\n",
    "# acc_KNN_del_missings = 0\n",
    "# f1_SVM_del_missings = 0\n",
    "# acc_SVM_del_missings = 0\n",
    "# results_classification.loc[7] = ['LogisticRegression_delete_missings', 'task15', f1_LR_del_missings, acc_LR_del_missings]\n",
    "# results_classification.loc[8] = ['KNeighborsClassifier_delete_missings', 'task15', f1_KNN_del_missings, acc_KNN_del_missings]\n",
    "# results_classification.loc[9] = ['LinearSVC_delete_missings', 'task15', f1_SVM_del_missings, acc_SVM_del_missings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>245211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48836   33           Private  245211  Bachelors             13   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation   relationship  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife   \n",
       "...                   ...                ...            ...   \n",
       "48836       Never-married     Prof-specialty      Own-child   \n",
       "48837            Divorced     Prof-specialty  Not-in-family   \n",
       "48839  Married-civ-spouse     Prof-specialty        Husband   \n",
       "48840            Divorced       Adm-clerical      Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial        Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48836               White    Male             0             0              40   \n",
       "48837               White  Female             0             0              36   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  class  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3      United-States  <=50K  \n",
       "4               Cuba  <=50K  \n",
       "...              ...    ...  \n",
       "48836  United-States  <=50K  \n",
       "48837  United-States  <=50K  \n",
       "48839  United-States  <=50K  \n",
       "48840  United-States  <=50K  \n",
       "48841  United-States   >50K  \n",
       "\n",
       "[45222 rows x 15 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data.mask(data.eq('?')).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "f1_RF = 0\n",
    "acc_RF = 0\n",
    "f1_GB = 0\n",
    "acc_GB = 0\n",
    "results_classification.loc[10] = ['RandomForestClassifier', 'task16', f1_RF, acc_RF]\n",
    "results_classification.loc[11] = ['GradientBoostingClassifier', 'task16', f1_GB, acc_GB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Ваш код ###\n",
    "\n",
    "best_params = {}\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "f1_best = 0\n",
    "acc_best = 0\n",
    "results_classification.loc[12] = ['Best_Model', 'task17', f1_best, acc_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
