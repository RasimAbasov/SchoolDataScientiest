{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b60bcb-7b8c-4a14-8f6f-4a1d8415dead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'drive/My Drive/dataset_text.txt'\n"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class DatasetSeq2Seq(Dataset):\n",
        "    def __init__(self, file_name, train_lang='en', bos: str = '~', eos: str = '#'):\n",
        "\n",
        "        with open(file_name, 'r') as f:\n",
        "            train = f.readlines()\n",
        "\n",
        "        # init vocabs with spetial tokens\n",
        "        self.input_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n",
        "        self.output_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n",
        "\n",
        "        self.input_sequnces = []\n",
        "        self.output_sequnces = []\n",
        "\n",
        "        n_input = 3\n",
        "        n_output = 3\n",
        "        for line in train:\n",
        "            split_line = line.split('\\t')\n",
        "\n",
        "            sequence = [self.input_sequnces_vocab[bos]]\n",
        "\n",
        "            for char in split_line[0].strip():\n",
        "                if self.input_sequnces_vocab.get(char) is None:\n",
        "                    self.input_sequnces_vocab[char] = n_input\n",
        "                    n_input += 1\n",
        "                sequence.append(self.input_sequnces_vocab[char])\n",
        "            sequence.append(self.input_sequnces_vocab[eos])\n",
        "\n",
        "            target = [self.output_sequnces_vocab[bos]]\n",
        "            for char in split_line[2].strip():\n",
        "                if self.output_sequnces_vocab.get(char) is None:\n",
        "                    self.output_sequnces_vocab[char] = n_output\n",
        "                    n_output += 1\n",
        "                target.append(self.output_sequnces_vocab[char])\n",
        "            target.append(self.output_sequnces_vocab[eos])\n",
        "\n",
        "            self.input_sequnces.append(sequence)\n",
        "            self.output_sequnces.append(target)\n",
        "\n",
        "        self.target_decode = [k for k in self.output_sequnces_vocab.keys()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequnces)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.input_sequnces[index],\n",
        "            'target': self.output_sequnces[index],\n",
        "        }\n",
        "\n",
        "\n",
        "def collate_fn(input_data):\n",
        "    data = []\n",
        "    targets = []\n",
        "\n",
        "    for item in input_data:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        targets.append(torch.as_tensor(item['target']))\n",
        "\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "    data_mask = data > 0\n",
        "    targets_mask = targets > 0\n",
        "\n",
        "    return {'data': data, \n",
        "            'target': targets, \n",
        "            'data_mask': data_mask, \n",
        "            'targets_mask': targets_mask,\n",
        "            }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq2Seq(fn)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zXXXYP37gFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#    test = '17 ноября 2022 г.'\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.emb(x)\n",
        "        _, context = self.rnn(emb)\n",
        "\n",
        "        return context\n",
        "# 1 vector \n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id, n_iter = 20):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(hidden_dim, vocab_len)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.eos_id = eos_id\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def forward(self, context, target_sequence):\n",
        "        if self.training:\n",
        "            # traget sequence начиналась с bos, например ~2022-11-17\n",
        "            emb = self.emb(target_sequence)\n",
        "            dec_context, _ = self.rnn(emb, context)\n",
        "            pred = self.clf(self.do(dec_context))\n",
        "\n",
        "            return pred\n",
        "        else:\n",
        "            predicts = []\n",
        "            # в инференсе в target sequene будет только bos\n",
        "            predicted_token = target_sequence # [~]\n",
        "            i = 0\n",
        "            while predicted_token.item() != self.eos_id and i < self.n_iter:\n",
        "                emb = self.emb(predicted_token) \n",
        "                context, _ = self.rnn(emb, context) \n",
        "                pred = self.clf(self.do(context))\n",
        "                predicted_token = torch.argmax(pred, dim=-1)\n",
        "                predicts.append(predicted_token)\n",
        "                i += 1\n",
        "            \n",
        "            return torch.cat(predicts, dim=-1)\n",
        "\n",
        "   # 2022-11-17#     "
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateNormalizer(nn.Module):\n",
        "    def __init__(self, input_vocab_len, target_vocab_len, \n",
        "                 emb__dim, hidden_dim, eos_id):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_vocab_len, emb_dim, hidden_dim)\n",
        "        self.decoder = Decoder(target_vocab_len, emb_dim, hidden_dim, eos_id)\n",
        "\n",
        "    def forward(self, x, target_sequence):\n",
        "        context = self.encoder(x)\n",
        "        pred = self.decoder(context, target_sequence)\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "KTz2txO4LTZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "input_vocab_size = len(dataset.input_sequnces_vocab)\n",
        "target_vocab_size = len(dataset.output_sequnces_vocab)\n",
        "eos_id = dataset.output_sequnces_vocab['#']\n",
        "#TODO try to use other model parameters\n",
        "emb_dim = 128\n",
        "hidden = 256\n",
        "n_epochs = 20\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "K_PACmDaH8Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DateNormalizer(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVX0P0otIk4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bMsBeqV8GCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        target = batch['target'].to(device)\n",
        "        predicts = model(batch['data'].to(device), target[:, :-1])\n",
        "        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n",
        "                         target[:, 1:].reshape(-1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    test = '17 ноября 2016 г.'\n",
        "    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "    test_encoded = test_encoded.to(device)\n",
        "    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pred = model(test_encoded, bos_input)\n",
        "        model.train()\n",
        "    decode = list(dataset.output_sequnces_vocab.keys())\n",
        "    out_str = ''\n",
        "    for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "        out_str += decode[i]\n",
        "    print(out_str)\n",
        "\n",
        "    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2f3MATJ8GKb",
        "outputId": "cdd7f920-d4a6-4b45-dcf4-e9fb09765c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.6435515880584717\n",
            "1986-06-09#\n",
            "epoch: 1, step: 0, loss: 0.9323967695236206\n",
            "2016-06-06#\n",
            "epoch: 2, step: 0, loss: 0.8316783308982849\n",
            "2017-01-19#\n",
            "epoch: 3, step: 0, loss: 0.6996486186981201\n",
            "2016-07-12#\n",
            "epoch: 4, step: 0, loss: 0.6092305183410645\n",
            "2016-09-21#\n",
            "epoch: 5, step: 0, loss: 0.5716256499290466\n",
            "2016-06-14#\n",
            "epoch: 6, step: 0, loss: 0.5558145642280579\n",
            "2016-07-13#\n",
            "epoch: 7, step: 0, loss: 0.5374111533164978\n",
            "2016-11-21#\n",
            "epoch: 8, step: 0, loss: 0.4318406581878662\n",
            "2016-11-21#\n",
            "epoch: 9, step: 0, loss: 0.3435434103012085\n",
            "2016-11-17#\n",
            "epoch: 10, step: 0, loss: 0.2922822833061218\n",
            "2016-12-11#\n",
            "epoch: 11, step: 0, loss: 0.29315754771232605\n",
            "2016-12-16#\n",
            "epoch: 12, step: 0, loss: 0.15326042473316193\n",
            "2016-11-21#\n",
            "epoch: 13, step: 0, loss: 0.11320129781961441\n",
            "2016-11-17#\n",
            "epoch: 14, step: 0, loss: 0.061911772936582565\n",
            "2016-11-21#\n",
            "epoch: 15, step: 0, loss: 0.039976563304662704\n",
            "2016-11-21#\n",
            "epoch: 16, step: 0, loss: 0.024007968604564667\n",
            "2016-11-21#\n",
            "epoch: 17, step: 0, loss: 0.025466684252023697\n",
            "2016-11-21#\n",
            "epoch: 18, step: 0, loss: 0.01777086965739727\n",
            "2016-11-21#\n",
            "epoch: 19, step: 0, loss: 0.016885580494999886\n",
            "2016-11-21#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = '21 11 2019'\n",
        "test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "test_encoded = test_encoded.to(device)\n",
        "bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_pred = model(test_encoded, bos_input)\n",
        "    model.train()\n",
        "decode = list(dataset.output_sequnces_vocab.keys())\n",
        "out_str = ''\n",
        "for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "    out_str += decode[i]\n",
        "print(out_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX_HfQr6Zzra",
        "outputId": "20dd3d0d-8f73-4e47-e8a7-3dcf78b1fcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-11-27#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "soes4kIU8FDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4a58b9-37ac-465e-9d6c-56e8d2569712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, temperature=1, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        attn = torch.bmm(q, # B x T1 x V\n",
        "                         k.transpose(1, 2), # B x T2 x V -> B x V x T2\n",
        "                         ) # B x T1 x T2\n",
        "        attn = attn / self.temperature\n",
        "\n",
        "        if mask is not None:\n",
        "            # print(attn.size(), mask.size())\n",
        "            attn = attn.masked_fill(~mask, -np.inf)\n",
        "\n",
        "        attn = self.softmax(attn)\n",
        "\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(~mask, 0.)\n",
        "\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.bmm(attn, v) # B x T1 x T2 @ B x T1 x V\n",
        "\n",
        "        return output, attn"
      ],
      "metadata": {
        "id": "9PbgCjN48FRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EncoderAttn(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.emb(x)\n",
        "        full_context, context = self.rnn(emb)\n",
        "\n",
        "        return context, full_context\n",
        "# 1 vector \n",
        "\n",
        "\n",
        "class DecoderAttn(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id, n_iter = 20):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(2 * hidden_dim , vocab_len)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.eos_id = eos_id\n",
        "        self.n_iter = n_iter\n",
        "        self.attn = ScaledDotProductAttention()\n",
        "\n",
        "    def forward(self, context, target_sequence, enc_context):\n",
        "        if self.training:\n",
        "            # traget sequence начиналась с bos, например ~2022-11-17\n",
        "            emb = self.emb(target_sequence)\n",
        "            dec_context, _ = self.rnn(emb, context)\n",
        "            attn, attn_mtx = self.attn(dec_context, enc_context, enc_context)\n",
        "            pred = self.clf(self.do(torch.cat((dec_context, attn), dim=-1)))\n",
        "\n",
        "            return pred\n",
        "        else:\n",
        "            predicts = []\n",
        "            # в инференсе в target sequene будет только bos\n",
        "            predicted_token = target_sequence # [~]\n",
        "            i = 0\n",
        "            while predicted_token.item() != self.eos_id and i < self.n_iter:\n",
        "                emb = self.emb(predicted_token) \n",
        "                context, _ = self.rnn(emb, context)\n",
        "                attn, attn_mtx = self.attn(context, enc_context, enc_context) \n",
        "                pred = self.clf(self.do(torch.cat((context, attn), dim=-1)))\n",
        "                predicted_token = torch.argmax(pred, dim=-1)\n",
        "                predicts.append(predicted_token)\n",
        "                i += 1\n",
        "            \n",
        "            return torch.cat(predicts, dim=-1)\n"
      ],
      "metadata": {
        "id": "74gggSX58Fe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateNormalizerAttn(nn.Module):\n",
        "    def __init__(self, input_vocab_len, target_vocab_len, \n",
        "                 emb__dim, hidden_dim, eos_id):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderAttn(input_vocab_len, emb_dim, hidden_dim)\n",
        "        self.decoder = DecoderAttn(target_vocab_len, emb_dim, hidden_dim, eos_id)\n",
        "\n",
        "    def forward(self, x, target_sequence, mask=None):\n",
        "        context, all_hid = self.encoder(x)\n",
        "        pred = self.decoder(context, target_sequence, all_hid)\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "aSpU1B3rn55K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DateNormalizerAttn(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cSCaZvfpn6FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        target = batch['target'].to(device)\n",
        "        predicts = model(batch['data'].to(device), target[:, :-1])#, batch['data_mask'].to(device).unsqueeze(-1))\n",
        "        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n",
        "                         target[:, 1:].reshape(-1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    test = '17 ноября 1117 г.'\n",
        "    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "    test_encoded = test_encoded.to(device)\n",
        "    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pred = model(test_encoded, bos_input)\n",
        "        model.train()\n",
        "    decode = list(dataset.output_sequnces_vocab.keys())\n",
        "    out_str = ''\n",
        "    for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "        out_str += decode[i]\n",
        "    print(out_str)\n",
        "\n",
        "    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "id": "dHqoAJO_n6Qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d89a03d-f274-4108-f318-65b8282ae7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 0.0718703642487526\n",
            "17797-11-17#\n",
            "epoch: 1, step: 0, loss: 0.06557723134756088\n",
            "1777-11-17#\n",
            "epoch: 2, step: 0, loss: 0.04026917368173599\n",
            "1777-11-17#\n",
            "epoch: 3, step: 0, loss: 0.05634636804461479\n",
            "1777-11-17#\n",
            "epoch: 4, step: 0, loss: 0.0672856941819191\n",
            "1777-11-17#\n",
            "epoch: 5, step: 0, loss: 0.047594889998435974\n",
            "1977-11-11#\n",
            "epoch: 6, step: 0, loss: 0.056803375482559204\n",
            "1977-11-11#\n",
            "epoch: 7, step: 0, loss: 0.03923920914530754\n",
            "1977-11-11#\n",
            "epoch: 8, step: 0, loss: 0.04330570995807648\n",
            "1977-11-11#\n",
            "epoch: 9, step: 0, loss: 0.055095501244068146\n",
            "1977-11-11#\n",
            "epoch: 10, step: 0, loss: 0.04330611601471901\n",
            "1977-11-11#\n",
            "epoch: 11, step: 0, loss: 0.039025381207466125\n",
            "1977-11-11#\n",
            "epoch: 12, step: 0, loss: 0.04305577278137207\n",
            "1977-11-11#\n",
            "epoch: 13, step: 0, loss: 0.05774302780628204\n",
            "1977-11-11#\n",
            "epoch: 14, step: 0, loss: 0.03917933255434036\n",
            "1977-11-11#\n",
            "epoch: 15, step: 0, loss: 0.04619215056300163\n",
            "1977-11-11#\n",
            "epoch: 16, step: 0, loss: 0.03463716804981232\n",
            "1977-11-11#\n",
            "epoch: 17, step: 0, loss: 0.04106408730149269\n",
            "1977-11-11#\n",
            "epoch: 18, step: 0, loss: 0.05667410045862198\n",
            "1977-11-11#\n",
            "epoch: 19, step: 0, loss: 0.044231660664081573\n",
            "1977-11-17#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lRJEguzqSJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-57Jq-CW8NmD"
      }
    }
  ]
}